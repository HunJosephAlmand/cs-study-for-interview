## 용어 정리 
### 정렬 알고리즘별 시간복잡도 
![](https://i.imgur.com/GrJe0rU.png)

-   안정 정렬
    -   중복된 값이 입력 순서와 동일하게 정렬하는 정렬 알고리즘
    -   삽입정렬, 버블정렬, 병합정렬 등
- 불안정 정렬(Unstable Sort) 
    -   중복된 값이 입력 순서와 동일하지 않게 정렬되는 알고리즘
    -   퀵정렬, 선택정렬, 계수정렬 등


## 선택 정렬 
![](https://i.imgur.com/nVae38I.png)

### 정의
현재 위치에 들어갈 데이터를 찾아 선택하는 알고리즘
-   해당 순서에 원소를 넣을 위치는 이미 정해져 있고, 어떤 원소를 넣을지 선택하는 알고리즘
-   해당 자리를 선택하고 그 자리에 오는 값을 찾는 것

### 과정
1.  주어진 배열에서 최소값을 찾는다.
2.  그 값을 맨 앞에 위치한 값과 교체한다.
3.  맨 처음 위치를 뺀 나머지 배열을 같은 방법으로 교체한다.
이 때, 각 라운드를 진행 할 때마다 앞에서부터 한 개씩 정렬되기 때문에, 라운드가 진행 될 때마다 한 번씩 줄면서 비교하게 된다.
총 라운드는 배열 크기 - 1번 진행되고, 각 라운드별 비교 횟수는 배열 크기 - 라운드 횟수만큼 비교한다.

### 구현
```java
void selectionSort(int[] arr) {
    for (int i = 0; i < arr.length-1; i++) {
        int minIndex = i;

		// 최솟값을 갖고있는 인덱스 찾기 
        for (int j = i + 1; j < arr.length; j++) {
            if (arr[j] < arr[minIndex]) {
                minIndex = j;
            }
        }

		// i번째 값과 찾은 최솟값을 서로 교환
        swap(arr, minIndex, j);
    }
}

void swap(int[] arr, int i, int j) {  
    int temp = arr[i];  
    arr[i] = arr[j];  
    arr[j] = temp;  
}
```
1.  위치(Index)를 선택한다.
2.  i+1 번째 원소부터 선택한 위치의 값과 비교를 시작한다.
3.  오름차순이므로 현재 선택한 자리에 있는 값보다 순회하고 있는 값이 작다면, 위치를 갱신한다.
4.  반복문이 끝난 뒤에 minIndex에 선택한 위치에 들어가야하는 값의 위치를 갖고 있으므로 서로 교환한다.

### 시간복잡도
데이터의 개수가 n개라고 했을 때
-   첫번째 반복문 : 1 ~ (n-1) ⇒ n-1
-   두번째 반복문 : 2 ~ (n-1) ⇒ n-2
-   `(n-1) + (n-2) + … + 2 + 1 ⇒ n(n-1)/2`
비교하는 것이 상수 시간에 이루어진다는 가정 아래, n개의 주어진 배열을 정렬하는 데 O(N^2)만큼의 시간이 걸린다.
최선, 평균, 최악의 경우 시간복잡도는 **O(N^2)**으로 동일하다.

### 공간복잡도
주어진 배열 안에서 교환을 통해 이루어지니 O(N)이다.

### 장점
-   코드가 단순하다.
-   정렬을 위한 비교횟수는 많지만, 버블 정렬에 비해 교환하는 횟수가 적기 때문에 많은 교환이 일어나야 하는 자료상태에서 비교적 효율적이다.
-   버블 정렬과 마찬가지로 정렬하고자 하는 배열 안에서 교환하는 방식이므로, 다른 메모리 공간을 필요로 하지 않는다. ⇒ 제자리 정렬 (in - okace sorting)

### 단점
-   시간 복잡도가 O(N^2)이므로 비효율적이다.
-   **불안정 정렬(Unstable Sort)**이다.


## 거품 정렬 
![](https://i.imgur.com/AscKlJk.png)

### 정의
**서로 인접한 두 원소**의 대소를 비교하고, 조건에 맞지 않다면 자리를 교환하여 정렬하는 알고리즘

### 과정
> 오름차순 기준
1. 앞에서부터 현재 원소와 바로 다음의 원소를 비교한다. 
2. 현재 원소가 다음 원소보다 크면 원소를 교환한다. 
3. 다음 원소로 이동하여 해당 원소와 그 다음원소를 비교한다.
	- 1회전을 수행한 뒤 가장 큰 원소가 맨 뒤로 이동하므로 2회전에서는 맨 끝에 있는 원소는 정렬에서 제외하고, 2회전을 수행하고 나면 끝에서 두 번째 원소까지는 정렬에서 제외된다. 이렇게 1회전 수행할 때마다 정렬에서 제외되는 데이터가 하나씩 늘어나게 된다.

### 구현
```java
void bubbleSort(int[] arr) {
	// round는 배열 크기 - 1 만큼 진행
    for (int i = 1; i < arr.length; i++) {  // 1. 
	    // 각 라운드별 비교횟수는 배열 크기의 현재 라운드를 뺀 만큼 비교
        for (int j = 0; j < arr.length - i; j++) { // 2. 
            if (arr[j] > arr[j+1]) {  // 3. 
                int temp = arr[j + 1];
                arr[j + 1] = arr[j];
                arr[j] = temp;
            }
        }
    }
    return arr;
}
```

1.  제외될 원소의 갯수를 의미한다. 1회전이 끝난 후, 배열의 마지막 위치에는 가장 큰 원소가 위치하기 때문에 하나씩 증가시켜준다.
2.  원소를 비교할 index를 뽑을 반복문이다. j는 현재 원소를 가르키고 j+1은 다음 원소를 가르키게 되므로, j는 0부터 시작하게 된다.
3.  현재 가르키고 있는 두 원소의 대소를 비교한다. 해당 코드는 오름차순 정렬로 현재 원소보다 이전 원소가 더 크다면 이전 원소가 뒤로 가야하므로 서로 자리를 교환한다.


### 시간복잡도
`(n-1) + (n-2) + …. + 2 + 1 ⇒ n(n-1)/2` 이므로, O(N^2)이다.
또한, Bubble Sort는 정렬이 돼있던 안돼있던, 2개의 원소를 비교하기 때문에 최선, 평균, 최악의 경우 모두 시간복잡도가 O(N^2)으로 동일하다.
하지만 위 구현처럼 일반적인 경우에 해당하고 개선된 거품 정렬을 사용한다면 즉, 최선의 경우 O(N)으로 만들 수 있다. 

### 개선된 거품정렬 
각 라운드에서 비교수행을 할 때 원소가 교환되지 않는다면 이는 이미 정렬된 데이터라는 의미이기 때문에 정렬을 종료하면 된다. 즉, 각 라운드에서 비교수행을 했는지를 판단할 수 있는 변수를 하나 두면 된다. 
```java 
void bubble_sort(int[] arr) {  
    for (int i = 1; i < arr.length; i++) {  
  
        boolean isSwapped = false;  
  
        for (int j = 0; j < arr.length - i; i++) {  
            if (arr[j] > arr[j + 1]) {  
                swap(arr, j, j+1);  
                isSwapped = true;  
            }  
        }  
  
        if (!isSwapped) {  
            break;  
        }  
    }  
}  
  
void swap(int[] arr, int i, int j) {  
    int temp = arr[i];  
    arr[i] = arr[j];  
    arr[j] = temp;  
}
```


### 공간복잡도
주어진 배열 안에서 교환을 통해 이루어지니 O(N)이다.


### 장점
-   코드가 단순하다.
-   정렬하고자 하는 배열 안에서 교환하는 방식이므로, 다른 메모리 공간을 필요로 하지 않는다. ⇒ 제자리 정렬 (in - okace sorting)
-   안정 정렬(Stable Sort)이다.

### 단점
-   시간 복잡도가 O(N^2)이므로 비효율적이다.
-   불정렬 돼있지 않은 원소가 정렬 됐을 때의 자리로 가기 위해서, 교환 연산이 많이 일어나게 된다.
	- 삽입정렬이나 선택정렬과도 같은 시간복잡도이지만 교환횟수가 많아 더 많은 시간이 걸린다.


## 삽입 정렬 
![](https://i.imgur.com/xfEkndm.png)

### 정의
현재 비교하고자 하는 타겟과 그 이전의 원소들과 비교하며 자리를 교환하는 정렬 방법
-   2번째 원소부터 시작하여 그 앞(왼쪽)의 원소들과 비교하여 삽입할 위치를 지정한 후, 원소를 뒤로 옮기고 지정된 자리에 자료를 삽입하여 정렬하는 알고리즘
-   최선의 경우 O(N)이라는 효율성을 가지고 있다.

### 과정
> 오름차순 기준
1.  현재 타겟이 되는 숫자와 이전 위치에 있는 원소들을 비교한다. (첫 번째 타겟은 두 번째 원소부터 시작한다.)
2.  타겟이 되는 숫자가 이전 위치에 있던 원소보다 작다면 위치를 서로 교환한다.
3.  그 다음 타겟을 찾아 위와 같은 방법으로 반복한다.


### 구현
```java
void insertion_sort(int[] arr) {  
    for (int i = 1; i < arr.length; i++) {  // (1)
        int target = arr[i]; // 타겟 넘버  
  
        int prev = i - 1;  
  
        // 타겟이 이전 원소보다 크기 전까지 반복  
        while (prev >= 0 && target < arr[prev]) {   // (2)
            arr[prev + 1] = arr[prev];  // 이전 원소를 한 칸씩 뒤로 미룬다.  
            prev--;  
        }  
  
        /*  
         * 위 반복문에서 탈출 하는 경우 앞의 원소가 타겟보다 작다는 의미이므로          
         * 타겟 원소는 j번째 원소 뒤에 와야한다.         
         * 그러므로 타겟은 j+1에 위치하게 된다.         
         */        
         arr[prev + 1] = target;  //(3)
    }  
}
```
1.  첫 번째 원소 앞에는 어떤 원소도 갖고 있지 않기 때문에, 두 번째 위치부터 탐색을 시작한다. target에 임시로 해당 위치 값을 저장하고, prev에는 해당 위치의 이전 위치를 저장한다.
2.  이전 위치를 가르키는 prev가 음수가 되지 않고, 이전 위치의 값이 (1)번 과정에서 선택한 값보다 크다면, 서로 값을 교환해주고 prev를 더 이전 위치를 가리키도록 한다
3.  (2)번 과정이 끝나고 난 뒤, prev에는 현재 target값보다 작은 값들 중 제일 큰 값의 위치를 가리키게 된다. 따라서 (prev+1)에 target값을 삽입해준다.

### 시간복잡도
데이터가 N개이고, i가 타겟이 되는 인덱스라고 할 때
- i = 2일 때, 데이터 비교 횟수는 2 - 1 = 1번 
- i = 3 일 떼, 데이터 비교 횟수는 3 - 1 = 2번 
- ... 
- i = N일 때, 데이터 비교 횟수는 N-1번
즉, 최악의 경우(역으로 정렬되어 있을 경우) 선택 정렬과 마찬가지로 `T(N) = (n-1) + (n-2) + …. + 2 + 1 ⇒ n(n-1)/2` 이므로, **O(N^2)** 이다
하지만, 모두 정렬이 되어 있는 경우에는, 한번씩 밖에 비교를 안하므로 O(N)의 시간복잡도를 가지게 된다.
또한, 이미 정렬되어 있는 배열에 자료를 하나씩 삽입,제거하는 경우에는, 현실적으로 최고의 정렬 알고리즘이 되는데, 탐색을 제외한 오버헤드가 매우 적기 때문이다. 즉, 거품 정렬나 선택 정렬와 이론상 같은 시간복잡도를 갖음에도 평균 비교 횟수에 대한 기댓값이 상대적으로 적기 때문에 평균 시간복잡도가 O(N^2)인 정렬 알고리즘 중에서는 빠른 편에 속한다.
최선의 경우 O(N)의 시간복잡도를 갖고, 평균과 최악의 경우 O(N^2)의 시간복잡도를 가지게 된다.


### 공간복잡도
주어진 배열 안에서 교환을 통해 이루어지니 O(N)이다.

### 장점
- 코드가 단순하다.
- 대부분의 원소가 이미 정렬되어 있다면 매우 효율적일 수 있다. O(N)
- 정렬하고자 하는 배열 안에서 교환하는 방식이므로, 다른 메모리 공간을 필요로 하지 않는다. => 제자리 정렬 (in-place sorting)
- 안정 정렬이다. 
- 선택정렬이나 거품 정렬과 같은 O(N^2) 알고리즘에 비교하여 상대적으로 빠르다.

### 단점 
- 평균과 최악의 시간복잡도가 O(n^2)으로 비효율적이다. 
- 데이터의 상태에 따라서 성능 편차가 매우 크다.
- 선택정렬이나 거품 정렬과 마찬가지로, 배열의 길이가 길어질수록 비효율적이다.



## 병합 정렬 
![](https://i.imgur.com/dpHERhh.png)
![](https://i.imgur.com/VQJsa8v.png)


### 정의 
문제를 분할하고, 분할한 문제를 정복하여 합치는 분할 정복 알고리즘을 기반으로 정렬되는 방식 
정렬해야 할 리스트가 주어지면 해당 리스트를 분할을 반복하여 최대한 작게 쪼개진 시점에 부분리스트에서 인접한 원소들끼리 비교하여 정렬하는 방식
비교 정렬이며 안정정렬이다. 제자리 정렬은 아니다.
> 분할 정복(divide and conquer) 방법
문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략이다.
분할 정복 방법은 대개 순환 호출을 이용하여 구현한다.


### 과정
1. 주어진 리스트를 절반으로 분할하여 부분리스트로 나눈다. (Divide : 분할)
2. 해당 부분리스트의 길이가 1이 아니라면 1번 과정을 되풀이한다. 
3. 인접한 부분리스트끼리 정렬하여 합친다. (Conqure : 정복)
![](https://i.imgur.com/FPt1Bnt.png)
반드시 2개의 부분리스트로 나누어야 한다. 
각각의 부분리스트는 정렬된 상태이다. 즉, 이미 **합병의 대상이 되는 두 영역이 각 영역에 대해서 정렬이 되어있기 때문**에 단순히 두 배열을 **순차적으로 비교하면서 정렬할 수가 있다.**

### 구현 
```java
static int[] sorted; // 합치는 과정에서 정렬하여 원소를 담을 임시배열  
  
public void merge_sort(int[] arr) {  
    sorted = new int[arr.length];  
    merge_sort(arr, 0, arr.length - 1);  
}  
  
private void merge_sort(int[] arr, int left, int right) {  
    /*  
     * left == right 즉, 부분리스트가 1개의 원소만 갖고있는 경우     
     * 더이상 쪼갤 수 없으므로 return     
     */    
     if (left == right) {  
        return;  
    }  
  
    int mid = (left + right) / 2;  // 절반 index  
  
    merge_sort(arr, left, mid);  // 절반 중 왼쪽  
    merge_sort(arr, mid + 1, right);  // 절반 중 오른쪽  
  
    merge(arr, left, mid, right);  
}  
  
// 합칠 부분리스트는 arr배열의 left ~ right 까지이다.  
private void merge(int[] arr, int left, int mid, int right) {  
    int l = left;        // 왼쪽 부분리스트 시작점  
    int r = mid + 1;     // 오른쪽 부분리스트의 시작점  
    int idx = left;      // 채워넣을 배열의 인덱스  
  
    while (l <= mid && r <= right) {  
        /*  
         * 왼쪽 부분리스트 l번째 원소가 오른쪽 부분리스트 r번째 원소보다 작거나 같을 경우        * 왼쪽의 l번째 원소를 새 배열에 넣고 l과 idx를 1 증가시킨다.        
         */        if (arr[l] <= arr[r]) {  
            sorted[idx] = arr[l];  
            idx++;  
            l++;  
        }  
        /*  
         * 위와 반대로 왼쪽 원소가 더 클 경우         */        else {  
            sorted[idx] = arr[r];  
            idx++;  
            r++;  
        }  
    }  
  
    /*  
     * 왼쪽 부분리스트가 먼저 모두 새 배열에 채워진 경우 (l > mid)     
     * 즉, 오른쪽 부분리스트에 아직 원소가 남아있을 경우     
     * 오른쪽 부분리스트의 나머지 원소들을 새 배열에 채워넣는다.     
     */    
     if (l > mid) {  
        while (r <= right) {  
            sorted[idx] = arr[r];  
            idx++;  
            r++;  
        }  
	}
	/*  
	 * 위와 반대로 왼쪽 부분리스트에 아직 원소가 남아있을 경우         
	 */    
	 else {  
        while (l <= mid) {  
            sorted[idx] = arr[l];  
            idx++;  
            l++;  
        }  
    }  
  
    // 정렬된 새 배열을 기존의 배열에 복사하여 옮겨준다.  
    for (int i = left; i <= right; i++) {  
        arr[i] = sorted[i];  
    }  
}
```

```java
public void mergeSort(int[] arr, int left, int right) {  
    if (left < right) {  
        int mid = (left + right) / 2;  
  
        mergeSort(arr, left, mid);  
        mergeSort(arr, mid + 1, right);  
        merge(arr, left, mid, right);  
    }  
}  
  
private void merge(int[] arr, int left, int mid, int rigth) {  
    int[] L = Arrays.copyOfRange(arr, left, mid + 1);  
    int[] R = Arrays.copyOfRange(arr, mid + 1, rigth + 1);  
  
    int leftIndex = 0;  
    int rigthIndex = 0;  
    int copyIndex = 0;  
    int leftLength = L.length;  
    int rightLength = R.length;  
  
    while (leftIndex < leftLength && rigthIndex < rightLength) {  
        if (L[leftIndex] <= R[rigthIndex]) {  
            arr[copyIndex++] = L[leftIndex++];  
        } else {  
            arr[copyIndex++] = R[rigthIndex];  
        }  
    }  
  
    while (leftIndex < leftLength) {  
        arr[copyIndex++] = L[leftIndex++];  
    }  
  
    while (rigthIndex < rightLength) {  
        arr[copyIndex++] = R[rigthIndex++];  
    }  
}
```

- Bottom - Up 방식
```java

static int[] sorted;  
  
public void merge_sort(int[] arr) {  
    sorted = new int[arr.length];  
    merge_sort(arr, 0, arr.length - 1);  
}  
  
public void merge_sort(int[] arr, int left, int right) {  
  
    // 1 - 2 - 4 - 8 .... 식으로 1부터 서브리스트를 나누는 기준을 두배씩 늘린다.  
    for (int size = 1; size <= right; size += size) {  
        /*  
         * 두 부분리스트을 순서대로 병합한다..         
         * 예를 들어 현재 부분리스트의 크기가 1일때         
         * 왼쪽 부분리스트 (low ~ mid) 와 오른쪽 부분리스트(mid + 1  ~ high)일 경우         
         * 왼쪽 부분리스트는 low = mid = 0이고,         
         * 오른쪽 부분리스트는 mid+1부터 low + (2 * size) - 1 = 1 이 된다.                 
         * 이 때 high가 배열의 인덱스를 넘어갈 수 도 있으니 right와 둘 중        
         * 작은 값이 병합되도록 해야한다.
         */                  
         for (int l = 0; l <= right - size; l += (2 * size)) {  
            int low = l;  
            int mid = l + size - 1;  
            int high = Math.min(l + (2 * size) - 1, right);  
            merge(arr, low, mid, high);  
        }  
    }  
}

private void merge(int[] arr, int left, int mid, int right) {  
	// 동일
}
```

### 시간복잡도
![](https://i.imgur.com/bCxzKt8.png)
N개의 데이터가 있는 리스트를 분할하여 1개까지 쪼개게 된다면 이진트리형태로 나온다는 것을 알 수 있다. 
그렇기에 N개의 노드에 대한 이진트리의 높이(h)는 O(logN)의 시간복잡도를 갖는다.
이제는 비교 및 정렬 과정을 생각해보자. 
위에서 두 개의 서브리스트을 sorted배열에 합치는 merge과정을 살펴보자. 
이미 두 서비리스트는 정렬된 형태라 앞 원소부터 차례대로 비교하며 할당해주기만 하면 된다. 즉, 아무리 최악의 상황이어도 두 개의 서브리스트 원소 개수만큼의 비교 및 새 배열로 할당되게 된다. 
그렇다면 i번째 레벨에서 노드의 개수가 2^i이고, 노드의 크기 즉, 한 노드에 들어있는 원소 개수는 N/2^i개다. 
이를 곱하면 한 레벨에서 비교작업에 대한 시간 복잡도는 O(2^i X N/2^i)이고 이는 곧 O(N)이 된다. 
그리고 O(N)의 비교작업을 트리의 높이인 logN - 1 번 수행하므로 다음과 같이 표기할 수 있다. O(N) X O(logN)

최종적으로 위를 계산하게 되면 O(NlogN)의 시간복잡도를 가짐을 알 수 있다.

### 장점 
- 항상 두 부분리스트를 쪼개어 들어가기 때문에 최악의 경우에도 시간복잡도가 O(NlogN)으로 유지된다. 
- 안정정렬이다. 

### 단점 
- 정렬과정에서 추가적인 보조 배열 공간을 사용하기 때문에 메모리 사용량이 많다. 
	- 제자리 정렬이 아니다.
- 보조 배열에서 원본배열로 복사하는 과정은 매우 많은 시간을 소비하기 때문에 데이터가 많을 경우 상대적으로 시간이 많이 소요된다.
	- 하지만 레코드를 연결 리스트로 구성하면, 링크 인덱스만 변경하면 되므로 데이터의 이동은 무시할 수 있을 정도로 작아진다. 
		- 제자리 정렬로 구현할 수 있다.
	- 따라서 크기가 큰 레코드를 정렬할 경우에 연결 리스트를 사용한다면, 합병 정렬은 퀵 정렬을 포함한 다른 어떤 정렬 방법보다 효율적이다.

### 퀵 정렬과 차이점 
퀵 정렬은 우선 피벗을 통해 정렬하는 것으로 영역을 쪼개서 하는 반면 합병정렬은 영역을 쪼갤 수 있을 만큼 쪼개고 정렬한다는 점이 다르다. 
그렇기 때문에 합병정렬은 순차적인 비교로 정렬을 진행하므로, LinkedList의 정렬이 필요할 때 사용하면 효율적이다. 
만약 LinkedList를 퀵정렬에 사용하게 되면 순차 접근이 아닌 임의 접근 특성때문에 성능이 좋지 않게 된다. LinkedList는 삽입,삭제 시에 효율적이지만 조회 연산에서는 비효율적이기 때문이다.


## 퀵 정렬 
![](https://i.imgur.com/0a2cSWh.png)

### 정의 
하나의 리스트를 피벗을 기준으로 두 개의 부분리스트로 나누어 하나는 피벗보다 작은 값들의 부분리스트, 다른 하나는 피벗보다 큰 값들의 부분리스트로 정렬한 다음, 각 부분리스트에 대해 다시 위처럼 재귀적으로 수행하여 정렬하는 방법 
병합 정렬과 마찬가지로 분할 정복 알고리즘이다.
다만, 병합정렬의 경우 하나의 리스트를 절반으로 나누어 분할 정복을 하고, 퀵 정렬은 피벗의 값에 따라 피벗보다 작은 값을 갖는 부분리스트와 피벗보다 큰 값을 갖는 부분리스트의 크기가 다를 수 있기 때문에 하나의 리스트에 대해 비균등하게 나뉜다는 점이 있다.
불안정 정렬에 속하며, 다른 원소와의 비교만으로 정렬을 수행하는 비교 정렬에 속한다.


### 과정 
1. 피벗을 하나 선택한다. 
2. 피벗을 기준으로 양쪽에서 피벗보다 큰 값, 혹은 작은 값을 찾는다. 왼쪽에서부터는 피벗보다 큰 값을 찾고, 오른쪽에서부터는 피벗보다 작은 값을 찾는다.
3. 양 방향에서 찾은 두 원소를 교환한다. 
4. 왼쪽에서 탐색하는 위치와 오른쪽에서 탐색하는 위치가 엇갈리지 않을 때까지 2번으로 돌아가 위 과정을 반복한다. 
5. 엇갈린 기점을 기준으로 두 개의 부분리스트로 나누어 1번으로 돌아가 해당 부분리스트의 길이가 1이 아닐 때 까지 1번 과정을 반복한다. (Divide : 분할)
6. 인접한 부분리스트끼리 합친다. (Conqure : 정복)

피벗을 선택하는 과정은 대표적으로 현재 부분배열의 가장 왼쪽 원소가 피벗이 되는 방법, 중간 원소가 피벗이 되는 방법, 마지막 원소가 피벗이 되는 방법이 있다.
핵심은 피벗을 하나 설정하고 피벗보다 작은 값들은 왼쪽에, 큰 값들은 오른쪽에 치중하도록 하는 것이다. 이 과정을 파티셔닝이라고 한다. 
파티셔닝을 했다면 파티셔닝을 통해 배치된 피벗의 위치를 기준으로 좌우 부분리스트로 나누어 각각의 리스트에 대해 재귀호출을 해주면 된다.

### 구현
> 왼쪽 피벗 선택 방식 기준 

```java
/**  
 * * @param arr 정렬할 배열  
 * @param lo 현재 부분배열의 왼쪽  
 * @param hi 현재 부분배열의 오른쪽  
 */
 void pivot_sort(int[] arr, int lo, int hi) {  
    /*  
     * lo가 hi보다 크거나 같다면 정렬 할 원소가     
     * 1개 이하이므로 정렬하지 않고 return     
     */    
    if (lo >= hi) {  
        return;  
    }  
  
    /*  
     * 피벗을 기준을 요소들이 왼쪽과 오른쪽으로 약하게 정렬된 상태로     
     * 만들어 준 뒤, 최종적으로 pivot의 위치를 얻는다.     
     * 
     * 그리고나서 해당 피벗을 기준으로 왼쪽 부분리스트와 오른쪽 부분리스트로 나누어 
     * 분할 정복을 해준다.     
     */    
	int pivot = partition(arr, lo, hi);  
  
    pivot_sort(arr, lo, pivot - 1);  
    pivot_sort(arr, pivot + 1, hi);  
}  
  
private int partition(int[] arr, int left, int right) {  
    int lo = left;  
    int hi = right;  
    int pivot = arr[left]; // 부분리스트의 왼쪽 요소를 피벗으로 설정  
  
    // lo가 hi보다 작을 때 까지만 반복    
    while (lo < hi) {  
        /*  
         * hi가 lo보다 크면서, hi의 요소가 pivot보다 작거나 같은 원소를         
         * 찾을 때 까지 hi를 감소         
         */        
	    while (arr[pivot] > pivot && lo < hi) {  
            hi--;  
        }  
  
        /*  
         * hi가 lo보다 크면서, lo의 요소가 pivot보다 큰 원소를         
         * 찾을 때 까지 lo를 증가시킨다.         
         */        
	    while (arr[pivot] <= pivot && lo < hi) {  
            lo++;  
        }  
  
        // 교환될 두 요소를 찾았으면 두 요소를 바꾼다.  
        swap(arr, lo, hi);  
    }  
  
    /*  
     * 마지막으로 맨 처음 pivot으로 설정했던 위치(a[left])의 원소와     
     * lo가 가리키는 원소를 바꾼다.     
     */    
     swap(arr, left, lo);  
  
    // 두 요소가 교환되었다면 피벗이었던 요소는 lo에 위치하므로 lo를 반환  
    return lo;  
}  
  
void swap(int[] arr, int i, int j) {  
    int temp = arr[i];  
    arr[i] = arr[j];  
    arr[j] = temp;  
}
```

- 오른쪽 피벗은 역순으로 진행하면 된다. 

- 중간 피벗 선택 방식 
```java 
void pivot_sort(int[] arr, int lo, int hi) {  
    if (lo >= hi) {  
        return;  
    }  
  
    int pivot = partition(arr, lo, hi);  
  
    pivot_sort(arr, lo, pivot);  
    pivot_sort(arr, pivot + 1, hi);  
}  
  
private int partition(int[] arr, int left, int right) {  
    // lo와 hi는 각각 배열의 끝에서 1 벗어난 위치부터 시작  
    int lo = left - 1;  
    int hi = right + 1;  
    int pivot = arr[(left + right) / 2]; // 부분리스트의 중간 요소를 피벗으로 설정  
  
    // lo가 hi보다 작을 때 까지만 반복    
    while (true) {  
        /*  
         * 1 증가시키고 난 뒤의 lo 위치의 요소가 pivot보다 큰 요소를         
         * 찾을 때 까지 반복한다.         
         */        
	    do {  
            lo++;  
        } while (arr[lo] < pivot);  
  
        /*  
         * 1 감소시키고 난 뒤의 hi 위치가 lo보다 크거나 같은 위치이면서         
         * hi위치의 요소가 pivot보다 작은 요소를 찾을 때까지 반복한다.         
         */        
		do {  
			hi--;  
        } while (arr[hi] > pivot && lo <= hi);  
  
        /*  
         * 만약 hi가 lo보다 크지 않다면 즉, 엇갈린다면         
         * swap하지 않고 hi를 리턴한다.         
         */        
	    if (lo >= hi) {  
            return hi;  
        }  
  
        // 교환될 두 요소를 찾았으면 두 요소를 바꾼다.  
        swap(arr, lo, hi);  
    }  
}  
  
void swap(int[] arr, int i, int j) {  
    int temp = arr[i];  
    arr[i] = arr[j];  
    arr[j] = temp;  
}
```
- 중간 위치를 피벗으로 설정하게 되면 hi가 가리키는 위치가 pivot의 위치보다 높으면서 hi가 가리키는 원소가 pivot보다 작은 경우가 생긴다. 
- 그렇기 때문에 파티셔닝을 통해 얻은 피벗까지 포함하여 부분리스트로 나누어야 한다.
![](https://i.imgur.com/If7epe6.png)



### 시간복잡도 
### 최선인 경우 : T(n) = O(nlog₂n)
![](https://i.imgur.com/XOyGoE4.png)
-   **비교횟수 : logn**
    -   레코드의 개수 n이 2의 거듭제곱이라고 가정했을 때, n= 2^3의 경우, 2^3 → 2^2 → 2^1 → 2^0 순으로 줄어들어 순환 호출의 깊이가 3임을 알 수 있다.
    -   이것을 일반화하면 n=2^k의 경우, k(k=logn)임을 알 수 있다.
-   **각 순환 호출 단계의 비교 연산 : n**
    -   각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균n번 정도의 비교가 이루어진다.
-   따라서, 최선의 시간복잡도는 `순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = nlogn`가 된다. 이동 횟수는 비교 횟수보다 적으므로 무시할 수 있다.
    

#### 최악의 경우 : T(n) = O(n^2)
![](https://i.imgur.com/IcUceyn.png)
-  최악의 경우는 정렬하고자 하는 배열이 오름차순 정렬되어있거나 내림차순 정렬되어 있는 경우이다.
- N개가 있는 리스트에 대해 가장 왼쪽 요소를 pivot을 잡고, pivot보다 작은 요소는 왼쪽에, 큰 요소는 오른쪽에 위치시켜 두 부분리스트로 나누게 된다. 이때 만약 pivot이 가장 작은 요소였다면 왼쪽의 부분리스트는 없고, N-1개의 요소를 갖는 오른쪽 부분리스트만 생성될 것이다.
-   **비교 횟수 : n**    
    -   레코드의 개수가 n이 2의 거듭제곱이라고 가정했을 때, 순환 호출의 깊이는 n임을 알 수 있다.
-   **각 순환 호출 단계의 비교 연산 : n**
    -   각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.
-   따라서, 최악의 시간복잡도는 `순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = n^2` 된다. 이동 횟수는 비교 횟수보다 적으므로 무시할 수 있다.
    

#### 평균의 경우 : T(n) = O(nlog₂n)

### 공간복잡도
주어진 배열 안에서 교환(swap)을 통해, 정렬이 수행되므로 O(n)이다.


### 퀵 정렬 개선 
partition() 함수에서 피벗 값이 최소나 최대값으로 지정되어 파티션이 나누어지지 않았을 때, 즉, 정렬하고자 하는 배열이 오름차순 정렬되어있거나 내림차순 정렬되어있으면 O(n^2)의 시간복잡도를 가진다.
이때, 배열에서 가장 앞에 있는 값과 중간값을 교환해준다면 확률적으로나마 시간복잡도 O(nlog₂n)으로 개선할 수 있다. 
하지만, 이 방법으로 개선한다 해도 퀵 정렬의 최악의 시간복잡도가 O(nlog₂n)으로 바뀌는 것은 아니다.

아니면 중간 피벗 방식을 사용하면 거의 정렬된 배열이더라도 거의 중간지점에 가까운 위치에서 왼쪽 리스트와 오른쪽 리스트가 균형에 가까운 트리를 얻어낼 수 있다.

그럼 왜 다른 O(NlogN) 정렬 방법들에 비해 빠를까? 
기본적으로 쉘 정렬이나 퀵 정렬은 정렬 방식이 멀리 떨어진 요소와 교환되는 정렬 방식이다. 
퀵 소트는 양 끝에서 피벗을 기준으로 피벗보다 작은 값을 갖는 위치에 있어야 할 원소가 피벗보다 크거나, 그 반대의 경우 서로 원소를 교환하는 방식이다. 
이러한 방식은 해당 원소가 최종적으로 있어야 할 위치에 거의 근접하게 위치하도록 하기 때문에 효율이 좋은 것이다. 
예로들어 9번째 원소가 3번째에 위치해야 한다고 할 때, 보통의 경우 9 → 8 → 7 → 6 → 5 → 4 → 3 이런식으로 자기가 현재 있는 위치와 바로 직전의 원소와 교환되면서 총 6번에 걸쳐 이동을 했었어야 한다면, Shell Sort나 Quick Sort의 경우 9 → 1 -> 4 -> 3 서로 떨어져있는 비연속적 원소가 교환되면서 원래 있어야 할 위치에 거의 근접하게 위치하도록 하기 때문에 빠른 정렬이 가능한 것이다.



### 장점 
- 평균 시간 복잡도는 O(NlogN)이며, 다른 O(NlogN)알고리즘에 비해 대채적으로 속도가 빠르다.
- 추가적인 별도의 메모리를 필요로 하지 않는 제자리 정렬이며 재귀 호출 스택프레임에 의한 공간복잡도는 logN으로 메모리를 적게 소비한다.

### 단점
- 불안정 정렬이다.
- 특정 조건하에 성능이 급격하게 떨어진다. 
	- 정렬된 배열에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.
- 재귀를 사용하기 때문에 재귀를 사용하지 못하는 환경일 경우 그 구현이 매우 복잡해진다.

### 결론
평균적으로 가장 빠른 정렬 알고리즘이며, JAVA에서 Arrays.sort() 내부적으로도 Dual Pivot Quick Sort로 구현되어 있을 정도로 효율적인 알고리즘이다.
-   참고글
    -   **[[Java] Java의 정렬 알고리즘 - Arrays와 Collections](https://sabarada.tistory.com/138)**
-   Tim sort
    -   [Tim sort에 대해 알아보자](https://d2.naver.com/helloworld/0315536)

## 힙 정렬
> 힙 
> 최솟값 또는 최댓값을 빠르게 찾아내기 위해 완전이진트리 형태로 만들어진 자료구조 
> 부모 노드는 항상 자식 노드보다 우선순위가 높다는 조건을 만족한다
반 정렬상태이다.

트리 구조를 구현할 때 연결리스트를 사용해도 되지만 배열을 사용하면 특정 노드의 검색, 이동 과정이 좀 더 효율적이다.


### 정의 
힙 자료구조를 기반으로한 정렬 방식이다.

### 과정 
1. 정렬해야 할 n개의 요소들로 최대 힙을 만든다. 
2. 그 다음으로 한 번에 하나의 요소를 힙에서 꺼내서 배열에 저장한다. 
3. 힙의 사이즈가 1보다 크면 위 과정을 반복한다.
힙을 만들기 위한 별도의 공간을 마련하는 것은 메모리를 그만큼 따로 잡아줘야 하기 때문에 비효율적이다. (우선순위 큐 사용시)
그래서 기존 배열을 힙 트리 상태로 만들고 정렬을 시킨다.

### 과정 상세 
![](https://i.imgur.com/8TJL6lL.png)
오름차순 정렬을 위해 최대힙으로 만들어준다. 힙의 경우 형제노드 사이에서의 우선순위는 고려되지 않는 반 정렬 상태이기 때문에 오름차순으로 구현 시 최소힙으로 정렬하게 되면 제대로 정렬되지 않을 수 있기 때문이다.
![](https://i.imgur.com/z0A9ibs.png)

#### 1. 최대 힙 만들기 
> 추가적인 메모리 공간을 생성하지 않고 원본 배열 안에서 정렬

![](https://i.imgur.com/rikR2ZD.png)

'가장 작은 서브트리부터 최대 힙을 만족하도록 순차적으로 진행한다. 이 과정을 heapify 라고 한다. 

```java
public class HeapSort {  
  
    // 힙을 만드는 함수  
    private void heapify(int[] arr, int parentIdx, int lastIdx) {  
  
        /*  
         * 현재 트리에서 부모 노드의 자식노드 인덱스를 각각 구한다.         
         * 현재 부모 인덱스를 가장 큰 값을 갖고 있다고 가정한다.         
         */        
        int leftChildIdx = 2 * parentIdx + 1;  
        int rightChildIdx = 2 * parentIdx + 2;  
        int largestIdx = parentIdx;  
  
        /*  
         * 왼쪽 자식 노드와 비교                  
         * 자식노드 인덱스가 끝의 원소 인덱스를 넘어가지 않으면서         
         * 현재 가장 큰 인덱스보다 왼쪽 자식노드의 값이 더 클경우         
         * 가장 큰 인덱스를 가리키는 largestIdx를 왼쪽 자식노드인덱스로 바꾼다.         
         */        
         if (leftChildIdx < lastIdx && arr[largestIdx] < arr[leftChildIdx]) {  
            largestIdx = leftChildIdx;  
        }  
  
        /*  
         * 오른쪽 자식 노드와 비교                  
         * 위의 과정과 마찬가지         
         */        
         if (rightChildIdx < lastIdx && arr[largestIdx] < arr[rightChildIdx]) {  
            largestIdx = rightChildIdx;  
        }  
  
  
        /*  
         * largestIdx와 부모노드가 같지 않다는 것은         
         * 위 자식노드 비교 과정에서 현재 부모노드보다 큰 노드가 존재한다는 뜻이다.        
         * 그럴 경우 해당 자식 노드와 부모 노드를 교환해주고         
         * 교환된 자식노드를 부모노드로 삼은 서브트리를 검사하도록 재귀 호출한다.         
         */        
		if (parentIdx != largestIdx) {  
            swap(arr, largestIdx, parentIdx);  
            heapify(arr, largestIdx, lastIdx);  
        }  
    }  
  
    private int getParent(int child) {  
        return (child - 1) / 2;  
    }  
  
    private void swap(int[] a, int i, int j) {  
        int temp = a[i];  
        a[i] = a[j];  
        a[j] = temp;  
    }  
}
```

함수를 구현했지만 이 함수는 어떻게 호출해야할까? 
가장 첫번째로 검사하는 노드는 `가장 마지막 노드의 부모 노드 서브트리`이다. 
{3, 7, 5, 4, 2, 8}에서 가장 마지막 노드는 8이고 인덱스는 배열 사이즈 - 1 = 5 이다. 그러므로 그의 부모 노드 인덱스는 (size - 1) / 2의 결과인 2이다.
즉, 인덱스가 2부터 시작하여 그에 대한 서브트리에 대해 힙을 만족시킨다. 그리고 서브트리가 힙을 만족하게 되면, 다음 검사할 노드인 인덱스 1의 노드에대해 서브트리를 검사하면 된다. 
정리하면 arr[2] -> arr[1] -> arr[0] 순으로 서브트리를 검사하는 것이다. 

```java 
public void heapSort(int[] arr) {  
    int size = arr.length;  
  
    /*  
     * 부모노드와 heaify과정에서 음수가 발생할 경우 잘못된 참조가 발생한다.     
     * 즉, 원소가 1개이거나 0개일 경우는 정렬 할 필요가 없으므로 바로 함수를 종료한다.     
     */    
    if (size < 2) {  
        return;  
    }  
  
    // 가장 마지막 노드의 부모 노드 인덱스  
    int parentIdx = getParent(size - 1);  
  
    // 최대 힙 만들기  
    for (int i = parentIdx; i >= 0; i--) {  
        heapify(arr, i, size - 1);  
    }  
}
```

#### 2. 정렬하기
![](https://i.imgur.com/vitUkPZ.png)
최대 힙을 만들었으니 이제 오름차순으로 정렬해줘야 한다. 
최대 힙은 항상 루트 노드가 최댓값을 갖고 있다. 이점을 이용하여 그 최대값을 하나씩 삭제하면서 배열의 맨 뒤부터 채워나간다. 
정리하면 root 원소를 배열의 뒤로 보냄 -> 뒤에 채운 원소를 제외한 나머지 배열 원소들을 다시 최대힙을 만족하도록 재구성 이 된다.

```java
public void heapSort(int[] arr) {  
    int size = arr.length;  
    
    if (size < 2) {  
        return;  
    }  
  
    
    int parentIdx = getParent(size - 1);  
  
    
    for (int i = parentIdx; i >= 0; i--) {  
  
        // 부모노드(i값)을 1씩 줄이면서 heap조건을 만족시키도록 재구성  
        heapify(arr, i, size - 1);  
    }  
  
    //정렬과정  
    for (int i = size - 1; i > 0; i--) {  
        /*  
         * root인 0번째 인덱스와 i번째 인덱스의 값을 교환한 뒤         
         * 0 ~ i-1 까지의 부분트리에 대해 최대힙을 만족하도록   
         * 재구성  
         */        
        swap(arr, 0, i);  
        heapify(arr, 0, i - 1);  
    }  
}
```

#### 개선하기 
heapify 메서드는 재귀호출을 하고 있다. 재귀호출은 StackOverFlow가 발생할 문제점과 메모리를 많이 잡아먹는 문제점이 있다. 
반복문 형식으로 개선해보자 
```java 
private void heapify(int[] arr, int parentIdx, int lastIdx) {  
  
    int leftChildIdx;  
    int rightChildIdx;  
    int largestIdx;  
  
    /*  
     * 현재 부모 인덱스의 자식 노드 인덱스가     
     * 마지막 인덱스를 넘지 않을 때 까지 반복한다.         
     * 
     * 이 때 왼쪽 자식 노드를 기준으로 해야 한다.     
     * 오른쪽 자식 노드를 기준으로 범위를 검사하게 되면     
     * 마지막 부모 인덱스가 왼쪽 자식만 갖고 있을 경우     
     * 왼쪽 자식노드와는 비교 및 교환을 할 수 없기 때문이다.     
     */    
     while ((parentIdx * 2) + 1 <= lastIdx) {  
        leftChildIdx = (parentIdx * 2) + 1;  
        rightChildIdx = (parentIdx * 2) + 2;  
        largestIdx = parentIdx;  
  
        /*  
         * left child node와 비교         
         * (범위는 while문에서 검사했으므로 별도 검사 필요 없음)         
         */        
	    if (arr[leftChildIdx] > arr[largestIdx]) {  
            largestIdx = leftChildIdx;  
        }  
  
        /*  
         * right child node와 비교         
         * right child node는 범위를 검사해주어야한다.         
         */        
         if (rightChildIdx <= lastIdx && arr[rightChildIdx] > arr[largestIdx]) {  
            largestIdx = rightChildIdx;  
        }  
  
        /*  
         * 교환이 발생했을 경우 두 원소를 교체 한 후         
         * 교환이 된 자식노드를 부모 노드가 되도록 교체한다.         
         */        
         if (largestIdx != parentIdx) {  
            swap(arr, parentIdx, largestIdx);  
            parentIdx = largestIdx;  
        } else {  
            return;  
        }  
    }  
}
```




### 시간복잡도
결론적으로 O(NlogN)을 유지한다. 
이해하려면 먼저 노드의 개수와 트리의 높이 사이의 상관관계를 알아야 한다. 
이진트리는 매 번 차수가 (h)가 증가할 때마다 2의 배수씩 추가된다. 
- d = 1 -> 노드 개수 1
- d = 2 -> 노드 개수 ( 1 + 2 ) 
- d = 3 -> 노드 개수 ( 1 + 2 + 4 )
- d = n -< 노드 개수 ( 1 + 2 + ... + 2^n-1 )
즉, 트리의 차수(레벨) d에 대하여 노드의 개수는 N = 2^d - 1 로 표현이 가능하다. 
노드의 개수에 대해 높이는 구하고자 하면 높이는 차수 - 1 이므로 h = log(N)이라는 계산이 나오게 된다. 

이를 바탕으로 시간복잡도를 구해보자 
1. heapify를 통해 초기 배열을 최대 힙으로 만드는 과정 
2. root노드를 뒤로 넘기고(삭제) 나머지 원소들을 힙으로 만드는 과정

일단 heapify 경우 트리의 깊이만큼 비교 교환이 이루어지므로 O(logN)의 시간복잡도를 가진다. 
![](https://i.imgur.com/6iv6FjD.png)
![](https://i.imgur.com/V1tvl53.png)



위의 그림을 보면 h에 대해 힙으로 만드는 총 비용을 알 수 있다. 
![](https://i.imgur.com/5DJrscE.png)
즉, h높이에 대해서 각 가질 수 있는 부분트리의 개수와 h높이에서 heapify에 걸리는 시간 o(h)가 걸린다는 뜻이다.
해당 식은 결과적으로 O(N) 시간복잡도를 가지게 된다. 

마지막으로 삭제하면서 힙을 유지할 땐 시간복잡도가 어떻게 될까?
![](https://i.imgur.com/hWrFtgp.png)

맨 뒤의 원소로 루트원소를 보내고 그 대신 그 자리에 있던 원소를 가져온다. 
그리고나서 힙을 재구성하는 데, 3 원소가 트리의 높이(h=2)까지 비교 및 교환을 한다. 즉, 어떤 원소를 삭제하고 힙을 재구성 하는 과정은 최악의 경우 트리의 높이만큼 비용이 발생한다. 
그래서 단일 수행에서 최악의 경우 트리의 높이 즉, log(N)만큼 발생한다는 것이다 .

위의 단일 수행을 N개의 원소만큼 반복하기 때문에 결론적으로 O(Nlog(N))의 시간복잡도를 가지게 된다. 
![](https://i.imgur.com/UP0gsVi.png)
모든 과정을 계산해보면 O(NlogN)의 시간복잡도를 가지게 된다.


### 장점 
- 최악의 경우에도 O(NlogN)으로 유지된다. 
- 힙의 특징상 부분 정렬을 할 때 효과가 좋다. 
	- 가장 큰 값 몇개만 필요할 때

### 단점 
- 일반적인 O(NlogN)정렬 알고리즘에 비해 성능은 약간 떨어진다. 
- 한 번 최대힙을 만들면서 불안정 정렬 상태에서 최대값만 가지고 정렬 하기 때문에 안정 정렬이 아니다.


## 출처 
- https://st-lab.tistory.com